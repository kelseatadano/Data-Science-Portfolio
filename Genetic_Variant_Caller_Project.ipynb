{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZTQ_a5CiGHn7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44dccaaf-8ee5-498e-ae92-d5a771ea73a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysam\n",
            "  Downloading pysam-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Downloading pysam-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl (25.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.1/25.1 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pysam\n",
            "Successfully installed pysam-0.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pysam\n",
        "import pysam\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from google.colab import files\n",
        "\n",
        "bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "bam_reads_index_file = '/content/drive/My Drive/out_sort.bam.bai'\n",
        "reference_chr_file = '/content/drive/My Drive/chr1_1e6_2e6.fasta'\n",
        "raw_reads_1_file = '/content/drive/My Drive/out.bwa.read1.fastq.gz'\n",
        "raw_reads_2_file = '/content/drive/My Drive/out.bwa.read2.fastq.gz'\n",
        "snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "snps = pd.read_csv('/content/drive/My Drive/putatative_snps.tsv', sep='\\t')\n",
        "\n",
        "snps.head()\n",
        "\n",
        "# Open BAM file\n",
        "bam_file = pysam.AlignmentFile('/content/drive/My Drive/out_sort.bam', \"rb\")\n",
        "\n",
        "# Open FASTA file (if needed for reference sequences)\n",
        "fasta_file = pysam.FastaFile('/content/drive/My Drive/chr1_1e6_2e6.fasta')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avL_QuGhbyhf",
        "outputId": "b61209eb-fe28-476a-c986-b324546344a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pysam\n",
        "import numpy as np\n",
        "\n",
        "def main():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "    snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "    # Load SNP data\n",
        "    snps = pd.read_csv(snps_file, sep='\\t')\n",
        "\n",
        "    # Open BAM file\n",
        "    bam_file = pysam.AlignmentFile(bam_reads_file, \"rb\")\n",
        "\n",
        "    # Function to get read counts and quality scores\n",
        "    def get_read_counts_and_quality_scores(bam_file, chrom, pos):\n",
        "        n_ref = 0\n",
        "        n_alt = 0\n",
        "        qual_scores = []\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos):\n",
        "            if pileupcolumn.pos == pos-1:\n",
        "                for pileupread in pileupcolumn.pileups:\n",
        "                    if not pileupread.is_del and not pileupread.is_refskip:\n",
        "                        base = pileupread.alignment.query_sequence[pileupread.query_position]\n",
        "                        ref_base = row['ref']\n",
        "                        alt_base = row['alt']\n",
        "                        if base == ref_base:\n",
        "                            n_ref += 1\n",
        "                        elif base == alt_base:\n",
        "                            n_alt += 1\n",
        "                        qual_scores.append(pileupread.alignment.query_qualities[pileupread.query_position])\n",
        "        error_rate = np.mean([10 ** (-q / 10) for q in qual_scores]) if qual_scores else 0.01\n",
        "        return n_ref, n_alt, error_rate\n",
        "\n",
        "    # Bayesian calculation of posteriors\n",
        "    def calculate_posterior(n_ref, n_alt, ref, alt, maf, error_rate):\n",
        "        # Prior probabilities based on Hardy-Weinberg Equilibrium\n",
        "        P_AA = (1 - maf) ** 2\n",
        "        P_AB = 2 * maf * (1 - maf)\n",
        "        P_BB = maf ** 2\n",
        "\n",
        "        # Likelihoods with error rates\n",
        "        P_data_given_AA = ((1 - error_rate) ** n_ref) * (error_rate ** n_alt)\n",
        "        P_data_given_AB = 0.5 ** (n_ref + n_alt)\n",
        "        P_data_given_BB = ((1 - error_rate) ** n_alt) * (error_rate ** n_ref)\n",
        "\n",
        "        # Bayes' Theorem\n",
        "        P_data = P_data_given_AA * P_AA + P_data_given_AB * P_AB + P_data_given_BB * P_BB\n",
        "        return {\n",
        "            ref+ref: P_data_given_AA * P_AA / P_data,\n",
        "            ref+alt: P_data_given_AB * P_AB / P_data,\n",
        "            alt+alt: P_data_given_BB * P_BB / P_data\n",
        "        }\n",
        "\n",
        "    results = []\n",
        "    for index, row in snps.iterrows():\n",
        "        chrom = row['chr']\n",
        "        pos = int(row['pos'])\n",
        "        maf = row['maf'] if not pd.isna(row['maf']) else 0.5\n",
        "\n",
        "        n_ref, n_alt, error_rate = get_read_counts_and_quality_scores(bam_file, chrom, pos)\n",
        "        posteriors = calculate_posterior(n_ref, n_alt, row['ref'], row['alt'], maf, error_rate)\n",
        "        results.append({\n",
        "            'chromosome': chrom,\n",
        "            'position': pos,\n",
        "            'putative_genotype': max(posteriors, key=posteriors.get),\n",
        "            'posterior_probability': max(posteriors.values()),\n",
        "            'n_reads': n_ref + n_alt\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_csv_path = results_df.to_csv('/content/drive/My Drive/snp_caller_results9.csv', index=False)\n",
        "    print(results_df.head())\n",
        "\n",
        "    bam_file.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOxa1xpfEy9C",
        "outputId": "09d1a795-4343-498c-9853-112dce6ee574"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "             chromosome  position putative_genotype  posterior_probability  \\\n",
            "0  chr1:1000000-2000000    172741                AA               0.902500   \n",
            "1  chr1:1000000-2000000    325026                CC               0.688900   \n",
            "2  chr1:1000000-2000000    375797                AA               0.894754   \n",
            "3  chr1:1000000-2000000    423797                TA               0.836288   \n",
            "4  chr1:1000000-2000000    518726                CG               0.501136   \n",
            "\n",
            "   n_reads  \n",
            "0        0  \n",
            "1        0  \n",
            "2        1  \n",
            "3        2  \n",
            "4        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define file paths\n",
        "    bam_reads_file = '/content/drive/My Drive/out_sort.bam'\n",
        "    snps_file = '/content/drive/My Drive/putatative_snps.tsv'\n",
        "\n",
        "    # Load SNP data from a TSV file\n",
        "    snps = pd.read_csv(snps_file, sep='\\t')\n",
        "\n",
        "    # Open the BAM file using pysam\n",
        "    bam_file = pysam.AlignmentFile(bam_reads_file, \"rb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InaUPz3vk-df",
        "outputId": "f4598ade-d218-4192-ecd6-be41146a9578"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "import pandas as pd\n",
        "\n",
        "def count_reads_at_positions(bam_file_path, positions):\n",
        "    \"\"\"\n",
        "    Count reads in a BAM file at specified positions.\n",
        "\n",
        "    Parameters:\n",
        "        bam_file_path (str): Path to the BAM file.\n",
        "        positions (list of tuples): List of tuples where each tuple is (chromosome, position).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with keys as (chromosome, position) and values as read counts.\n",
        "    \"\"\"\n",
        "    # Open the BAM file\n",
        "    bam_file = pysam.AlignmentFile(bam_file_path, \"rb\")\n",
        "    read_counts = {}\n",
        "\n",
        "    # Iterate through each specified position\n",
        "    for chrom, pos in positions:\n",
        "        count = 0\n",
        "        # Fetch reads overlapping the position (0-based indexing adjustment)\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos, truncate=True):\n",
        "            if pileupcolumn.pos == pos - 1:\n",
        "                count = pileupcolumn.nsegments\n",
        "        read_counts[(chrom, pos)] = count\n",
        "\n",
        "    # Close the BAM file\n",
        "    bam_file.close()\n",
        "    return read_counts\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    positions_to_check = [(\"chr1:1000000-2000000\", 172741), (\"chr1:1000000-2000000\", 325026), (\"chr1:1000000-2000000\", 375797)]  # Add your positions here\n",
        "\n",
        "    # Path to your BAM file\n",
        "    bam_file_path = '/content/drive/My Drive/out_sort.bam'\n",
        "\n",
        "    # Get read counts\n",
        "    counts = count_reads_at_positions(bam_file_path, positions_to_check)\n",
        "\n",
        "    # Print results\n",
        "    for pos, count in counts.items():\n",
        "        print(f\"Position {pos}: {count} reads\")\n"
      ],
      "metadata": {
        "id": "RDEcV_R8snxm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a4ee0bc-096c-4a5d-8a6e-cb1aa4008f10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position ('chr1:1000000-2000000', 172741): 5 reads\n",
            "Position ('chr1:1000000-2000000', 325026): 3 reads\n",
            "Position ('chr1:1000000-2000000', 375797): 8 reads\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "import pandas as pd\n",
        "\n",
        "def verify_read_counts(bam_file_path, positions, ref_alt_pairs):\n",
        "    \"\"\"\n",
        "    Verifies read counts at specified positions using pysam and compares with expected counts.\n",
        "\n",
        "    Parameters:\n",
        "        bam_file_path (str): Path to the BAM file.\n",
        "        positions (list): List of positions (chromosome, position) to check.\n",
        "        ref_alt_pairs (dict): Dictionary with (chromosome, position) as key and (ref, alt) as value.\n",
        "\n",
        "    Returns:\n",
        "        None: Prints the results directly.\n",
        "    \"\"\"\n",
        "    bam_file = pysam.AlignmentFile(bam_file_path, \"rb\")\n",
        "\n",
        "    for chrom, pos in positions:\n",
        "        n_ref, n_alt = 0, 0\n",
        "        ref, alt = ref_alt_pairs[(chrom, pos)]\n",
        "\n",
        "        for pileupcolumn in bam_file.pileup(chrom, pos-1, pos, truncate=True):\n",
        "            if pileupcolumn.pos == pos - 1:\n",
        "                for pileupread in pileupcolumn.pileups:\n",
        "                    if not pileupread.is_del and not pileupread.is_refskip:\n",
        "                        base = pileupread.alignment.query_sequence[pileupread.query_position]\n",
        "                        if base == ref:\n",
        "                            n_ref += 1\n",
        "                        elif base == alt:\n",
        "                            n_alt += 1\n",
        "\n",
        "        print(f\"Position: {chrom}:{pos}, Reference (Ref): {ref}, Alternate (Alt): {alt}\")\n",
        "        print(f\"Calculated n_ref: {n_ref}, n_alt: {n_alt}\")\n",
        "        print(\"----------\")\n",
        "\n",
        "    bam_file.close()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    bam_path = '/content/drive/My Drive/out_sort.bam'\n",
        "    # Example data - replace with your actual data\n",
        "    positions = [(\"chr1:1000000-2000000\", 172741), (\"chr1:1000000-2000000\", 325026), (\"chr1:1000000-2000000\", 375797), (\"chr1:1000000-2000000\", 423797), (\"chr1:1000000-2000000\", 518726), (\"chr1:1000000-2000000\", 568632), (\"chr1:1000000-2000000\", 868896)]  # List of tuples (chromosome, position)\n",
        "    ref_alt_pairs = {\n",
        "        (\"chr1:1000000-2000000\", 172741): (\"A\", \"G\"),\n",
        "        (\"chr1:1000000-2000000\", 325026): (\"T\", \"C\"),\n",
        "        (\"chr1:1000000-2000000\", 375797): (\"A\", \"T\"),\n",
        "        (\"chr1:1000000-2000000\", 423797): (\"T\", \"A\"),\n",
        "        (\"chr1:1000000-2000000\", 518726): (\"C\", \"G\"),\n",
        "        (\"chr1:1000000-2000000\", 568632): (\"A\", \"T\"),\n",
        "        (\"chr1:1000000-2000000\", 868896): (\"T\", \"A\")\n",
        "\n",
        "    }\n",
        "\n",
        "    verify_read_counts(bam_path, positions, ref_alt_pairs)\n"
      ],
      "metadata": {
        "id": "lMR0-9m0udQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740869ae-2e9d-428b-b38d-30d71e7a1fd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Position: chr1:1000000-2000000:172741, Reference (Ref): A, Alternate (Alt): G\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:325026, Reference (Ref): T, Alternate (Alt): C\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:375797, Reference (Ref): A, Alternate (Alt): T\n",
            "Calculated n_ref: 1, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:423797, Reference (Ref): T, Alternate (Alt): A\n",
            "Calculated n_ref: 0, n_alt: 2\n",
            "----------\n",
            "Position: chr1:1000000-2000000:518726, Reference (Ref): C, Alternate (Alt): G\n",
            "Calculated n_ref: 0, n_alt: 1\n",
            "----------\n",
            "Position: chr1:1000000-2000000:568632, Reference (Ref): A, Alternate (Alt): T\n",
            "Calculated n_ref: 0, n_alt: 0\n",
            "----------\n",
            "Position: chr1:1000000-2000000:868896, Reference (Ref): T, Alternate (Alt): A\n",
            "Calculated n_ref: 2, n_alt: 0\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Methods:\n",
        "\n",
        "1. **Mounting Google Drive**:\n",
        "   - This is essential for accessing files stored in Google Drive when running the script in Google Colab. It sets up the file system to access BAM files, reference files, and SNP data.\n",
        "\n",
        "2. **Reading SNP Data**:\n",
        "   - The script reads a tab-separated values (TSV) file containing SNP data into a pandas DataFrame. This is critical for fetching the SNP positions to be analyzed.\n",
        "\n",
        "3. **Opening Files with `pysam`**:\n",
        "   - **BAM File**: Opens a BAM file for reading aligned sequencing data. This is used to fetch alignment data at specific genomic positions.\n",
        "   - **FASTA File**: Optionally, a FASTA file is opened if reference sequences are needed for comparison or other analysis.\n",
        "\n",
        "4. **get_read_counts_and_quality_scores**:\n",
        "   - This function retrieves the number of reads aligning to reference (ref) and alternate (alt) alleles at specific positions within the genome. It also calculates the average error rate based on quality scores. This is crucial for understanding the coverage and quality of sequencing at positions of interest.\n",
        "\n",
        "5. **calculate_posterior**:\n",
        "   - Computes the posterior probabilities for genotype assignments based on observed allele counts, using a Bayesian model with priors based on Hardy-Weinberg Equilibrium. This method is central to determining the most likely genotypes at SNP positions.\n",
        "\n",
        "6. **Data Analysis and Export**:\n",
        "   - The script iterates through SNP positions, using the above functions to calculate read counts, error rates, and posterior probabilities. It then assembles these results into a DataFrame and exports this to a CSV file. This summarized data provides insights into potential genotypes and the reliability of these determinations based on sequencing data.\n",
        "\n",
        "### Auxiliary Functions:\n",
        "\n",
        "- **count_reads_at_positions**: Counts reads at specified genomic positions. Useful for preliminary checks of read coverage.\n",
        "- **verify_read_counts**: Compares observed read counts to expected counts based on reference and alternate alleles, providing a straightforward method to validate sequencing and alignment accuracy.\n",
        "\n",
        "### Main Results:\n",
        "\n",
        "The script outputs a DataFrame that lists SNPs along with calculated metrics such as the most likely genotype, its posterior probability, and the number of reads supporting each allele. This DataFrame is saved to a CSV file for further analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "_TR1ZnT2rbO3"
      }
    }
  ]
}